{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fa1482eb",
      "metadata": {
        "id": "fa1482eb"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f67jGL23fQbo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f67jGL23fQbo",
        "outputId": "77ddb833-5b22-40be-a578-705114f4a45a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Check if running in Google Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# Set dataset path accordingly\n",
        "if IN_COLAB:\n",
        "    ! git clone https://github.com/MrKiwix/IAPR-project.git\n",
        "    %cd IAPR-project\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    ROOT_DIR = Path('/content/drive/MyDrive')\n",
        "else:\n",
        "    ROOT_DIR = Path('./')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fcde645f",
      "metadata": {
        "id": "fcde645f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision.transforms import v2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from skimage import io, transform\n",
        "from src.helper import display_sample\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "15a0e5e4",
      "metadata": {
        "id": "15a0e5e4"
      },
      "outputs": [],
      "source": [
        "class ChocolateDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, label_csv, transform=None, target_transform=None):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.label_df = pd.read_csv(label_csv)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist\n",
        "\n",
        "        img_path = Path(f\"{self.data_dir}/L{self.label_df.iloc[idx, 0]}.JPG\")\n",
        "\n",
        "        image = io.imread(img_path)\n",
        "        label = self.label_df.iloc[idx, 1:]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class LabelToTensor:\n",
        "    def __call__(self, label):\n",
        "        return torch.tensor(label.to_numpy())\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Identity()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.shortcut(x)\n",
        "\n",
        "        # first conv layer, downsampling if stride > 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class CountHead(nn.Module):\n",
        "    \"\"\"\n",
        "    in_channels : #channels coming from the encoder\n",
        "    hidden      : size of the intermediate layer (default 512)\n",
        "    n_classes   : how many categories we count\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=512, hidden=512, n_classes=3, p_drop=0.2):\n",
        "        super().__init__()\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)           # (B, C, H, W) → (B, C, 1, 1)\n",
        "\n",
        "        self.regressor = nn.Sequential(              # (B, C) → (B, n_classes)\n",
        "            nn.Flatten(1),                           # (B, C, 1, 1) → (B, C)\n",
        "            nn.Linear(in_channels, hidden, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p_drop),\n",
        "            nn.Linear(hidden, n_classes, bias=True)  # final counts (float)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.gap(x)\n",
        "        return self.regressor(x)                     # shape (B, n_classes)\n",
        "\n",
        "\n",
        "class ChocoNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(64)\n",
        "        self.relu  = nn.ReLU(inplace=True)\n",
        "\n",
        "        # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(ResBlock, 64, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(ResBlock, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(ResBlock, 256, 2, stride=2)\n",
        "        self.layer4 = self._make_layer(ResBlock, 512, 2, stride=2)\n",
        "\n",
        "        self.head = CountHead(in_channels=512, n_classes=13)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.head(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            batch_size = X[0]\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1bf13173",
      "metadata": {
        "id": "1bf13173"
      },
      "outputs": [],
      "source": [
        "# -----------------  PREPARE THE DATA  -----------------\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "NUM_CLASSES = 13\n",
        "IMG_SIZE    = (120, 180)          # height, width  (change as you like)\n",
        "\n",
        "label_csv  = ROOT_DIR / Path(\"./data/train.csv\")\n",
        "images_dir = ROOT_DIR / Path(\"./data/train\")\n",
        "\n",
        "\"\"\"# transforms: uint8 [0-255] -> float32 [0-1]  + simple resize\n",
        "img_tf = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Resize(IMG_SIZE, antialias=True),\n",
        "])\"\"\"\n",
        "\n",
        "# 1) TRAIN transforms (with augmentation)\n",
        "train_tf = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True), \n",
        "    v2.Resize(IMG_SIZE, antialias=True),                \n",
        "    v2.RandomHorizontalFlip(0.5),\n",
        "    v2.RandomRotation(15),\n",
        "    v2.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    v2.Normalize(mean=[0.5]*3, std=[0.5]*3),\n",
        "])\n",
        "\n",
        "# 2) TEST/VALID transforms (no augmentation)\n",
        "test_tf = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Resize(IMG_SIZE, antialias=True),\n",
        "    v2.Normalize(mean=[0.5]*3, std=[0.5]*3),\n",
        "])\n",
        "\n",
        "\"\"\"dataset = ChocolateDataset(\n",
        "    data_dir=images_dir,\n",
        "    label_csv=label_csv,\n",
        "    transform=img_tf,\n",
        "    target_transform=LabelToTensor()\n",
        ")\n",
        "\n",
        "# split 80 % / 20 %\n",
        "train_len = int(0.8 * len(dataset))\n",
        "test_len  = len(dataset) - train_len\n",
        "train_ds, test_ds = random_split(dataset, [train_len, test_len],\n",
        "                                 generator=torch.Generator().manual_seed(42))\"\"\"\n",
        "\n",
        "# Full dataset\n",
        "full_dataset = ChocolateDataset(\n",
        "    data_dir=images_dir,\n",
        "    label_csv=label_csv,\n",
        "    transform=None,  # temp placeholder\n",
        "    target_transform=LabelToTensor()\n",
        ")\n",
        "\n",
        "# Split indexes\n",
        "train_len = int(0.8 * len(full_dataset))\n",
        "test_len  = len(full_dataset) - train_len\n",
        "train_idxs, test_idxs = torch.utils.data.random_split(\n",
        "    range(len(full_dataset)), [train_len, test_len], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "# Subset with transforms applied\n",
        "train_ds = torch.utils.data.Subset(\n",
        "    ChocolateDataset(images_dir, label_csv, transform=train_tf, target_transform=LabelToTensor()),\n",
        "    train_idxs)\n",
        "\n",
        "test_ds = torch.utils.data.Subset(\n",
        "    ChocolateDataset(images_dir, label_csv, transform=test_tf, target_transform=LabelToTensor()),\n",
        "    test_idxs)\n",
        "\n",
        "batch_size = 32\n",
        "num_workers = 0\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size,\n",
        "                          shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size,\n",
        "                          shuffle=False, num_workers=num_workers, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "23a4a346",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23a4a346",
        "outputId": "f13792b5-7c83-4ca6-c533-039f3846f4c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# -----------------  BUILD MODEL  -----------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = ChocoNetwork().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2a6d3969",
      "metadata": {
        "id": "2a6d3969"
      },
      "outputs": [],
      "source": [
        "# -----------------  OPTIMISER & SCHEDULER  -----------------\n",
        "\n",
        "# two parameter groups: head LR 1e-3, backbone LR 1e-4 (when unfrozen)\n",
        "optim_groups = [\n",
        "    {\"params\": [p for n, p in model.named_parameters() if n.startswith(\"head.\")],\n",
        "     \"lr\": 1e-3},\n",
        "    {\"params\": [p for n, p in model.named_parameters() if not n.startswith(\"head.\")],\n",
        "     \"lr\": 1e-4},\n",
        "]\n",
        "optimizer = torch.optim.AdamW(optim_groups, weight_decay=1e-4)\n",
        "\n",
        "# Smooth L1 (Huber) with β=1.0\n",
        "criterion = nn.SmoothL1Loss(beta=1.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "447d2386",
      "metadata": {
        "id": "447d2386"
      },
      "outputs": [],
      "source": [
        "# -----------------  TRAIN / EVAL LOOPS  -----------------\n",
        "def train_epoch(loader, net, loss_fn, optim, epoch):\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    for imgs, targets in loader:\n",
        "        imgs     = imgs.to(device, non_blocking=True)\n",
        "        targets  = targets.float().to(device, non_blocking=True)\n",
        "\n",
        "        preds = net(imgs)\n",
        "        loss  = loss_fn(preds, targets)\n",
        "\n",
        "        optim.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "    return running_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(loader, net, loss_fn):\n",
        "    net.eval()\n",
        "    total_loss = 0.0\n",
        "    mae_sum    = torch.zeros(NUM_CLASSES, device=device)\n",
        "\n",
        "    for imgs, targets in loader:\n",
        "        imgs    = imgs.to(device, non_blocking=True)\n",
        "        targets = targets.float().to(device, non_blocking=True)\n",
        "\n",
        "        preds = net(imgs)\n",
        "        total_loss += loss_fn(preds, targets).item() * imgs.size(0)\n",
        "\n",
        "        mae_sum += (preds - targets).abs().sum(dim=0)\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    mae      = (mae_sum / len(loader.dataset)).cpu()   # per-class MAE\n",
        "\n",
        "    return avg_loss, mae\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cd194c8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd194c8d",
        "outputId": "c4f64a7b-f293-4cde-99df-4506622fd24e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | train loss: 0.3568 | val loss: 0.3468 | val MAE/class: [0.58, 0.51, 0.45, 0.42, 0.51, 0.73, 0.51, 0.67, 0.41, 0.68, 0.67, 0.46, 0.79]\n",
            "Epoch 02 | train loss: 0.3234 | val loss: 0.3373 | val MAE/class: [0.60, 0.51, 0.47, 0.43, 0.51, 0.73, 0.51, 0.67, 0.44, 0.67, 0.67, 0.50, 0.78]\n",
            "Epoch 03 | train loss: 0.3127 | val loss: 0.3253 | val MAE/class: [0.65, 0.52, 0.49, 0.46, 0.51, 0.73, 0.54, 0.68, 0.46, 0.68, 0.68, 0.54, 0.78]\n",
            "Epoch 04 | train loss: 0.3043 | val loss: 0.3069 | val MAE/class: [0.67, 0.54, 0.50, 0.48, 0.55, 0.74, 0.51, 0.69, 0.47, 0.69, 0.69, 0.56, 0.78]\n",
            "Training complete.  Best val loss: 0.30690813064575195\n"
          ]
        }
      ],
      "source": [
        "# -----------------  TRAINING DRIVER  -----------------\n",
        "EPOCHS           = 4\n",
        "best_val_loss    = float(\"inf\")\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "\n",
        "    train_loss = train_epoch(train_loader, model, criterion, optimizer, epoch)\n",
        "    val_loss, val_mae = eval_epoch(test_loader, model, criterion)\n",
        "\n",
        "    # ---- logging ----\n",
        "    mae_str = \", \".join([f\"{m:.2f}\" for m in val_mae])\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"train loss: {train_loss:.4f} | \"\n",
        "          f\"val loss: {val_loss:.4f} | \"\n",
        "          f\"val MAE/class: [{mae_str}]\")\n",
        "\n",
        "    # save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best_choco_count.pt\")\n",
        "\n",
        "print(\"Training complete.  Best val loss:\", best_val_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ndM9O5ucbt_7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndM9O5ucbt_7",
        "outputId": "a65679dc-c495-4e6b-d855-0c10860a047f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference time: 7.55s\n",
            "tensor([[0.3616, 0.1808, 0.2106, 0.2471, 0.1755, 0.1694, 0.0309, 0.2461, 0.2299,\n",
            "         0.1209, 0.2116, 0.3278, 0.0457],\n",
            "        [0.3677, 0.1809, 0.2423, 0.2803, 0.2130, 0.1304, 0.0278, 0.2352, 0.2246,\n",
            "         0.1193, 0.2018, 0.3448, 0.0798],\n",
            "        [0.3545, 0.1727, 0.2273, 0.2727, 0.2055, 0.1438, 0.0338, 0.2339, 0.2321,\n",
            "         0.1231, 0.2019, 0.3475, 0.0729],\n",
            "        [0.3552, 0.1748, 0.2249, 0.2719, 0.2058, 0.1455, 0.0335, 0.2376, 0.2309,\n",
            "         0.1247, 0.2026, 0.3463, 0.0695],\n",
            "        [0.3630, 0.1812, 0.2101, 0.2453, 0.1710, 0.1738, 0.0303, 0.2484, 0.2282,\n",
            "         0.1183, 0.2126, 0.3239, 0.0403],\n",
            "        [0.3626, 0.1839, 0.2160, 0.2532, 0.1810, 0.1655, 0.0299, 0.2449, 0.2302,\n",
            "         0.1191, 0.2076, 0.3299, 0.0475],\n",
            "        [0.3614, 0.1800, 0.2134, 0.2535, 0.1816, 0.1620, 0.0331, 0.2448, 0.2302,\n",
            "         0.1227, 0.2097, 0.3308, 0.0499],\n",
            "        [0.3542, 0.1744, 0.2246, 0.2677, 0.1993, 0.1517, 0.0344, 0.2345, 0.2340,\n",
            "         0.1218, 0.2018, 0.3447, 0.0673],\n",
            "        [0.3546, 0.1729, 0.2293, 0.2773, 0.2099, 0.1388, 0.0340, 0.2350, 0.2306,\n",
            "         0.1240, 0.2003, 0.3494, 0.0753],\n",
            "        [0.3439, 0.1683, 0.2305, 0.2807, 0.2179, 0.1405, 0.0360, 0.2298, 0.2344,\n",
            "         0.1251, 0.1949, 0.3561, 0.0828],\n",
            "        [0.3462, 0.1719, 0.2279, 0.2765, 0.2135, 0.1425, 0.0352, 0.2335, 0.2326,\n",
            "         0.1259, 0.1973, 0.3523, 0.0778],\n",
            "        [0.3737, 0.1849, 0.2466, 0.2803, 0.2115, 0.1301, 0.0253, 0.2341, 0.2209,\n",
            "         0.1159, 0.2036, 0.3420, 0.0790],\n",
            "        [0.3411, 0.1670, 0.2238, 0.2756, 0.2104, 0.1474, 0.0382, 0.2316, 0.2372,\n",
            "         0.1269, 0.1962, 0.3541, 0.0788],\n",
            "        [0.3512, 0.1723, 0.2272, 0.2751, 0.2073, 0.1444, 0.0348, 0.2343, 0.2331,\n",
            "         0.1236, 0.1998, 0.3497, 0.0746],\n",
            "        [0.3740, 0.1848, 0.2471, 0.2809, 0.2122, 0.1297, 0.0253, 0.2337, 0.2206,\n",
            "         0.1156, 0.2032, 0.3422, 0.0794],\n",
            "        [0.3487, 0.1710, 0.2321, 0.2803, 0.2166, 0.1382, 0.0345, 0.2317, 0.2317,\n",
            "         0.1239, 0.1964, 0.3535, 0.0806],\n",
            "        [0.3447, 0.1679, 0.2262, 0.2778, 0.2130, 0.1434, 0.0369, 0.2320, 0.2352,\n",
            "         0.1274, 0.1969, 0.3538, 0.0793],\n",
            "        [0.3707, 0.1831, 0.2445, 0.2802, 0.2124, 0.1300, 0.0264, 0.2347, 0.2230,\n",
            "         0.1180, 0.2029, 0.3433, 0.0800]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "tic = time.time()\n",
        "model.load_state_dict(torch.load(\"best_choco_count.pt\"))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  pred = model(next(iter(test_loader))[0].to(device))\n",
        "\n",
        "print(f\"Inference time: {time.time() - tic:.2f}s\")\n",
        "\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "567d72ae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "CUDA devices: 1\n",
            "Current CUDA device index: 0\n",
            "Device name: NVIDIA GeForce GTX 1650 Ti with Max-Q Design\n"
          ]
        }
      ],
      "source": [
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"CUDA devices:\", torch.cuda.device_count())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current CUDA device index:\", torch.cuda.current_device())\n",
        "    print(\"Device name:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ZHm8kTIqifJt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHm8kTIqifJt",
        "outputId": "73522e05-ecb9-4d92-a106-eb6f9582b15e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([18, 13])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "zWm8HjBbilAr",
      "metadata": {
        "id": "zWm8HjBbilAr"
      },
      "outputs": [],
      "source": [
        "batch_sample = next(iter(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "TTeYb7e0ivz-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTeYb7e0ivz-",
        "outputId": "dd8d1c17-adf7-4721-a2d3-10c6507b40fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([18, 3, 120, 180])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_sample[0].shape"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl-cuda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
