{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa1482eb",
      "metadata": {
        "id": "fa1482eb"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f67jGL23fQbo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f67jGL23fQbo",
        "outputId": "77ddb833-5b22-40be-a578-705114f4a45a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Check if running in Google Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# Set dataset path accordingly\n",
        "if IN_COLAB:\n",
        "    ! git clone https://github.com/MrKiwix/IAPR-project.git\n",
        "    %cd IAPR-project\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    ROOT_DIR = Path('/content/drive/MyDrive')\n",
        "else:\n",
        "    ROOT_DIR = Path('./')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcde645f",
      "metadata": {
        "id": "fcde645f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision.transforms import v2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from skimage import io, transform\n",
        "from src.helper import display_sample\n",
        "from torch import nn\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15a0e5e4",
      "metadata": {
        "id": "15a0e5e4"
      },
      "outputs": [],
      "source": [
        "class ChocolateDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, label_csv, transform=None, target_transform=None):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.label_df = pd.read_csv(label_csv)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist\n",
        "\n",
        "        img_path = Path(f\"{self.data_dir}/L{self.label_df.iloc[idx, 0]}.JPG\")\n",
        "\n",
        "        image = io.imread(img_path)\n",
        "        label = self.label_df.iloc[idx, 1:]\n",
        "        label = label.astype(int)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class LabelToTensor:\n",
        "    def __call__(self, label):\n",
        "        return torch.tensor(label.to_numpy())\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Identity()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.shortcut(x)\n",
        "\n",
        "        # first conv layer, downsampling if stride > 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class CountHead(nn.Module):\n",
        "    \"\"\"\n",
        "    in_channels : #channels coming from the encoder\n",
        "    hidden      : size of the intermediate layer (default 512)\n",
        "    n_classes   : how many categories we count\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=512, hidden=512, n_classes=3, p_drop=0.2):\n",
        "        super().__init__()\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)           # (B, C, H, W) → (B, C, 1, 1)\n",
        "\n",
        "        self.regressor = nn.Sequential(              # (B, C) → (B, n_classes)\n",
        "            nn.Flatten(1),                           # (B, C, 1, 1) → (B, C)\n",
        "            nn.Linear(in_channels, hidden, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p_drop),\n",
        "            nn.Linear(hidden, n_classes, bias=True)  # final counts (float)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.gap(x)\n",
        "        return self.regressor(x)                     # shape (B, n_classes)\n",
        "\n",
        "\n",
        "class ChocoNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(64)\n",
        "        self.relu  = nn.ReLU(inplace=True)\n",
        "\n",
        "        # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(ResBlock, 64, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(ResBlock, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(ResBlock, 256, 2, stride=2)\n",
        "        self.layer4 = self._make_layer(ResBlock, 512, 2, stride=2)\n",
        "\n",
        "        self.head = CountHead(in_channels=512, n_classes=13)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.head(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            batch_size = X[0]\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf13173",
      "metadata": {
        "id": "1bf13173"
      },
      "outputs": [],
      "source": [
        "# -----------------  PREPARE THE DATA  -----------------\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "SYNTHETIC = True\n",
        "\n",
        "NUM_CLASSES = 13\n",
        "IMG_SIZE    = (120, 180)          # height, width  (change as you like)\n",
        "\n",
        "if SYNTHETIC:\n",
        "    label_csv  = ROOT_DIR / Path(\"./data/synthetic_train.csv\")\n",
        "    images_dir = ROOT_DIR / Path(\"./data/synthetic_train\")\n",
        "else:\n",
        "    label_csv  = ROOT_DIR / Path(\"./data/train.csv\")\n",
        "    images_dir = ROOT_DIR / Path(\"./data/train\")\n",
        "\n",
        "\"\"\"# transforms: uint8 [0-255] -> float32 [0-1]  + simple resize\n",
        "img_tf = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Resize(IMG_SIZE, antialias=True),\n",
        "])\"\"\"\n",
        "\n",
        "# 1) TRAIN transforms (with augmentation)\n",
        "train_tf = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True), \n",
        "    v2.Resize(IMG_SIZE, antialias=True),                \n",
        "    # v2.RandomHorizontalFlip(0.5),\n",
        "    # v2.RandomRotation(15),\n",
        "    # v2.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    v2.Normalize(mean=[0.5]*3, std=[0.5]*3),\n",
        "])\n",
        "\n",
        "# 2) TEST/VALID transforms (no augmentation)\n",
        "test_tf = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Resize(IMG_SIZE, antialias=True),\n",
        "    v2.Normalize(mean=[0.5]*3, std=[0.5]*3),\n",
        "])\n",
        "\n",
        "# Full dataset\n",
        "full_dataset = ChocolateDataset(\n",
        "    data_dir=images_dir,\n",
        "    label_csv=label_csv,\n",
        "    transform=None,\n",
        "    target_transform=LabelToTensor()\n",
        ")\n",
        "\n",
        "# Split indexes\n",
        "train_len = int(0.8 * len(full_dataset))\n",
        "test_len  = len(full_dataset) - train_len\n",
        "train_idxs, test_idxs = torch.utils.data.random_split(\n",
        "    range(len(full_dataset)), [train_len, test_len], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "# Subset with transforms applied\n",
        "train_ds = torch.utils.data.Subset(\n",
        "    ChocolateDataset(images_dir, label_csv, transform=train_tf, target_transform=LabelToTensor()),\n",
        "    train_idxs)\n",
        "\n",
        "test_ds = torch.utils.data.Subset(\n",
        "    ChocolateDataset(images_dir, label_csv, transform=test_tf, target_transform=LabelToTensor()),\n",
        "    test_idxs)\n",
        "\n",
        "batch_size = 32\n",
        "num_workers = 0\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size,\n",
        "                          shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size,\n",
        "                          shuffle=False, num_workers=num_workers, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23a4a346",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23a4a346",
        "outputId": "f13792b5-7c83-4ca6-c533-039f3846f4c9"
      },
      "outputs": [],
      "source": [
        "# -----------------  BUILD MODEL  -----------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = ChocoNetwork().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a6d3969",
      "metadata": {
        "id": "2a6d3969"
      },
      "outputs": [],
      "source": [
        "# -----------------  OPTIMISER & SCHEDULER  -----------------\n",
        "\n",
        "# two parameter groups: head LR 1e-3, backbone LR 1e-4\n",
        "optim_groups = [\n",
        "    {\"params\": [p for n, p in model.named_parameters() if n.startswith(\"head.\")],\n",
        "     \"lr\": 1e-3},\n",
        "    {\"params\": [p for n, p in model.named_parameters() if not n.startswith(\"head.\")],\n",
        "     \"lr\": 1e-4},\n",
        "]\n",
        "optimizer = torch.optim.AdamW(optim_groups, weight_decay=1e-4)\n",
        "\n",
        "# Smooth L1 (Huber) with β=1.0\n",
        "criterion = nn.SmoothL1Loss(beta=1.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70655547",
      "metadata": {},
      "outputs": [],
      "source": [
        "def f1_imagewise(y_true, y_pred, eps=1e-8):\n",
        "    \"\"\"\n",
        "    y_true : (B, C) tensor of int >= 0\n",
        "    y_pred : (B, C) tensor of float\n",
        "    \"\"\"\n",
        "    y_pred_int = y_pred.round().clamp_min_(0)\n",
        "    tp  = torch.min(y_true, y_pred_int).sum(dim=1)      # (B,)\n",
        "    fpn = (y_true - y_pred_int).abs().sum(dim=1)        # (B,)\n",
        "    f1  = (2 * tp) / (2 * tp + fpn + eps)               # (B,)\n",
        "    return f1.mean().item()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "447d2386",
      "metadata": {
        "id": "447d2386"
      },
      "outputs": [],
      "source": [
        "# -----------------  TRAIN / EVAL LOOPS  -----------------\n",
        "def train_epoch(loader, net, loss_fn, optim, epoch):\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    for imgs, targets in loader:\n",
        "        imgs     = imgs.to(device, non_blocking=True)\n",
        "        targets  = targets.float().to(device, non_blocking=True)\n",
        "\n",
        "        preds = net(imgs)\n",
        "        loss  = loss_fn(preds, targets)\n",
        "\n",
        "        optim.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "    return running_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(loader, net, loss_fn):\n",
        "    net.eval()\n",
        "    total_loss = 0.0\n",
        "    abs_err    = torch.zeros(NUM_CLASSES, device=device)\n",
        "    f1_sum     = 0.0\n",
        "\n",
        "    for imgs, targets in loader:\n",
        "        imgs    = imgs.to(device)\n",
        "        targets = targets.float().to(device)\n",
        "\n",
        "        preds = net(imgs)\n",
        "        total_loss += loss_fn(preds, targets).item() * imgs.size(0)\n",
        "        abs_err    += (preds.round() - targets).abs().sum(dim=0)\n",
        "        f1_sum     += f1_imagewise(targets, preds) * imgs.size(0)\n",
        "\n",
        "    n = len(loader.dataset)\n",
        "    avg_loss = total_loss / n\n",
        "    mae      = (abs_err / n).cpu()\n",
        "    avg_f1   = f1_sum / n\n",
        "\n",
        "    return avg_loss, mae, avg_f1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd194c8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd194c8d",
        "outputId": "c4f64a7b-f293-4cde-99df-4506622fd24e"
      },
      "outputs": [],
      "source": [
        "EPOCHS        = 60\n",
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "csv_path = \"training_log.csv\"\n",
        "N = 13  \n",
        "header = [\"epoch\", \"train_loss\", \"val_loss\"] + [f\"val_mae_class_{i+1}\" for i in range(N)] + [\"val_f1\"]\n",
        "\n",
        "with open(csv_path, \"w\", newline=\"\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(header)\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_loss = train_epoch(train_loader, model, criterion, optimizer)\n",
        "        val_loss, val_mae, val_f1 = eval_epoch(test_loader, model, criterion)\n",
        "\n",
        "        mae_str = \", \".join([f\"{m:.2f}\" for m in val_mae])\n",
        "        print(\n",
        "            f\"Epoch {epoch:02d} | \"\n",
        "            f\"train_loss: {train_loss:.4f} | \"\n",
        "            f\"val_loss: {val_loss:.4f} | \"\n",
        "            f\"val_MAE_per_class: [{mae_str}] | \"\n",
        "            f\"val_F1: {val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        # write one row of metrics\n",
        "        row = [epoch, train_loss, val_loss] + [float(f\"{m:.4f}\") for m in val_mae] + [val_f1]\n",
        "        writer.writerow(row)\n",
        "        csvfile.flush()\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), \"best_choco_count.pt\")\n",
        "\n",
        "\n",
        "print(\"Training complete.  Best val loss:\", best_val_loss)\n",
        "print(f\"All metrics have been logged to {csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25078d83",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"best_choco_model.pt\")\n",
        "files.download(csv_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl-cuda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
